"""
smart_backtest_v19.py

V19: å¤šçº§åˆ«ç¼ è®º + AI è¯„åˆ† + ç»“æ„åŒ–é£æ§ å›æµ‹å¼•æ“ï¼ˆé›å½¢å¯è·‘ç‰ˆï¼‰

è¯´æ˜ï¼š
- ä¾èµ– local_data_engine.load_local_kline() è¯»å–æœ¬åœ° K çº¿
- é»˜è®¤ä½¿ç”¨å¤šå‘¨æœŸï¼š4h / 1h / 15m / 5m
- æœ¬æ–‡ä»¶ç›®æ ‡ï¼šç»™å‡ºä¸€ä¸ªã€Œèƒ½è·‘é€š + ç»“æ„æ¸…æ™°ã€çš„ V19 ä¸»å¹²æ¡†æ¶
  æ–¹ä¾¿åç»­é€æ­¥æ›¿æ¢/å¢å¼ºå…·ä½“ç®—æ³•ç»†èŠ‚
"""

import argparse
import logging
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd

try:
    # ä¸ç¬¬ä¸€å­£ä¿æŒå…¼å®¹
    from local_data_engine import load_local_kline
except Exception as e:  # pragma: no cover - ä»…é˜²å¾¡æ€§å¤„ç†
    load_local_kline = None  # type: ignore

    def _missing_loader(*args, **kwargs):
        raise RuntimeError(
            "æœªæ‰¾åˆ° local_data_engine.load_local_klineï¼Œ"
            "è¯·ç¡®è®¤ local_data_engine.py åœ¨åŒä¸€ç›®å½•ï¼Œ"
            "å¹¶ä¸”åŒ…å«å‡½æ•° load_local_kline(symbol, interval, days)"
        )

    load_local_kline = _missing_loader  # type: ignore


# ===================== æ—¥å¿—é…ç½® =====================

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
)


# ===================== åŸºæœ¬æ•°æ®ç»“æ„ =====================


@dataclass
class Bi:
    start_index: int
    end_index: int
    direction: str  # "up" / "down"


@dataclass
class ZhongShu:
    start_index: int
    end_index: int
    high: float
    low: float


@dataclass
class ChanSignal:
    index: int               # åœ¨æ‰§è¡Œçº§åˆ«(5m)ä¸­çš„ç´¢å¼•
    price: float
    kind: str                # third_buy / third_sell / breakout_buy / breakout_sell ç­‰
    direction: str           # long / short
    score: float             # AI è¯„åˆ† 0~1
    rr: float                # æœŸæœ›æ”¶ç›Šé£é™©æ¯”
    sl: float                # æ­¢æŸä»·
    tp: float                # æ­¢ç›ˆä»·


@dataclass
class Trade:
    entry_index: int
    exit_index: int
    entry_price: float
    exit_price: float
    direction: str           # long / short

    @property
    def pnl(self) -> float:
        if self.direction == "long":
            return self.exit_price - self.entry_price
        else:
            return self.entry_price - self.exit_price


# ===================== å·¥å…·å‡½æ•° =====================


def ensure_ohlc(df: pd.DataFrame) -> pd.DataFrame:
    """ç¡®ä¿ DataFrame æ‹¥æœ‰ OHLC åˆ—å¹¶æŒ‰æ—¶é—´æ’åºã€è®¾ç½® DatetimeIndexã€‚"""
    if "timestamp" in df.columns:
        df = df.copy()
        df["timestamp"] = pd.to_datetime(df["timestamp"], unit="ms", errors="ignore")
        df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")
        df = df.dropna(subset=["timestamp"])
        df = df.sort_values("timestamp").set_index("timestamp")

    for col in ["open", "high", "low", "close"]:
        if col not in df.columns:
            raise ValueError(f"ç¼ºå°‘å¿…è¦åˆ—: {col}")

    # æœ‰äº›æ•°æ® index å·²ç»æ˜¯ DatetimeIndexï¼Œè¿™é‡Œåšä¸€æ¬¡å…œåº•
    if not isinstance(df.index, pd.DatetimeIndex):
        df = df.sort_index()
        df.index = pd.to_datetime(df.index)

    return df[["open", "high", "low", "close"]].copy()


# ===================== å•çº§åˆ«ç¼ è®ºç»“æ„ï¼ˆç®€åŒ–å¯è·‘ç‰ˆï¼‰ =====================


def detect_fractals(df: pd.DataFrame) -> Tuple[List[int], List[int]]:
    """
    ç®€åŒ–ç‰ˆåˆ†å‹æ£€æµ‹ï¼š
    - é¡¶åˆ†å‹ï¼šhigh[i] > high[i-1] & high[i] > high[i+1]
    - åº•åˆ†å‹ï¼šlow[i]  < low[i-1]  & low[i]  < low[i+1]
    """
    highs = df["high"].values
    lows = df["low"].values
    up_f: List[int] = []
    down_f: List[int] = []

    for i in range(2, len(df) - 2):
        if highs[i] > highs[i - 1] and highs[i] > highs[i + 1]:
            up_f.append(i)
        if lows[i] < lows[i - 1] and lows[i] < lows[i + 1]:
            down_f.append(i)

    return up_f, down_f


def detect_bis(
    df: pd.DataFrame,
    up_f: List[int],
    down_f: List[int],
    min_bi_height: float = 0.002,
) -> List[Bi]:
    """
    ç®€åŒ–ç‰ˆâ€œç¬”â€è¯†åˆ«é€»è¾‘ï¼š
    - ä½¿ç”¨é¡¶/åº•åˆ†å‹æŒ‰æ—¶é—´æ’åº
    - ç›¸é‚»ä¸¤ä¸ªåˆ†å‹è‹¥æ–¹å‘ä¸åŒã€ä¸”ä»·æ ¼å·®è¶…è¿‡é˜ˆå€¼åˆ™è§†ä¸ºä¸€ç¬”
    """
    highs = df["high"].values
    lows = df["low"].values

    all_f = sorted(set(up_f + down_f))
    if len(all_f) < 2:
        return []

    bis: List[Bi] = []

    def is_top(idx: int) -> bool:
        return idx in up_f

    def is_bottom(idx: int) -> bool:
        return idx in down_f

    last_idx = all_f[0]
    last_dir: Optional[str] = None

    for idx in all_f[1:]:
        if is_top(last_idx) and is_bottom(idx):
            # down ç¬”
            high_price = highs[last_idx]
            low_price = lows[idx]
            if (high_price - low_price) / high_price >= min_bi_height:
                if last_dir != "down":
                    bis.append(Bi(start_index=last_idx, end_index=idx, direction="down"))
                    last_dir = "down"
                    last_idx = idx
        elif is_bottom(last_idx) and is_top(idx):
            # up ç¬”
            low_price = lows[last_idx]
            high_price = highs[idx]
            if (high_price - low_price) / low_price >= min_bi_height:
                if last_dir != "up":
                    bis.append(Bi(start_index=last_idx, end_index=idx, direction="up"))
                    last_dir = "up"
                    last_idx = idx
        else:
            # åŒå‘åˆ†å‹ï¼Œæ‹©ä¼˜ä¿ç•™æå€¼
            if is_top(last_idx) and is_top(idx):
                if highs[idx] > highs[last_idx]:
                    last_idx = idx
            if is_bottom(last_idx) and is_bottom(idx):
                if lows[idx] < lows[last_idx]:
                    last_idx = idx

    return bis


def detect_zhongshu(df: pd.DataFrame, bis: List[Bi]) -> List[ZhongShu]:
    """
    æç®€ç‰ˆä¸­æ¢è¯†åˆ«ï¼š
    - è¿ç»­ä¸‰ç¬”çš„ä»·æ ¼é‡å åŒºé—´è§†ä¸ºä¸€ä¸ªä¸­æ¢
    - è¿™é‡Œåªç»™å‡ºä¸€ä¸ªè¿‘ä¼¼å¯è·‘ç‰ˆæœ¬ï¼Œåç»­å¯ä»¥æ›¿æ¢ä¸ºä½ æ›´ä¸¥è°¨çš„ç¼ è®ºå®ç°
    """
    zs_list: List[ZhongShu] = []
    highs = df["high"].values
    lows = df["low"].values

    if len(bis) < 3:
        return zs_list

    for i in range(len(bis) - 2):
        b1, b2, b3 = bis[i], bis[i + 1], bis[i + 2]

        high1 = max(highs[b1.start_index:b1.end_index + 1])
        low1 = min(lows[b1.start_index:b1.end_index + 1])
        high2 = max(highs[b2.start_index:b2.end_index + 1])
        low2 = min(lows[b2.start_index:b2.end_index + 1])
        high3 = max(highs[b3.start_index:b3.end_index + 1])
        low3 = min(lows[b3.start_index:b3.end_index + 1])

        upper = min(high1, high2, high3)
        lower = max(low1, low2, low3)

        if upper > lower:
            start_index = min(b1.start_index, b2.start_index, b3.start_index)
            end_index = max(b1.end_index, b2.end_index, b3.end_index)
            zs_list.append(ZhongShu(start_index=start_index, end_index=end_index, high=upper, low=lower))

    return zs_list


# ===================== å¤šçº§åˆ«ç»“æ„ä¸Šä¸‹æ–‡ =====================


@dataclass
class MultiLevelContext:
    symbol: str
    interval_dfs: Dict[str, pd.DataFrame]       # "4h" / "1h" / "15m" / "5m"
    bis: Dict[str, List[Bi]]
    zhongshus: Dict[str, List[ZhongShu]]


def build_multilevel_context(
    symbol: str,
    intervals: List[str],
    days: int,
) -> MultiLevelContext:
    """åŠ è½½å¤šå‘¨æœŸæ•°æ®å¹¶æ„å»ºåŸºç¡€ç¼ è®ºç»“æ„ã€‚"""
    interval_dfs: Dict[str, pd.DataFrame] = {}
    bis_map: Dict[str, List[Bi]] = {}
    zs_map: Dict[str, List[ZhongShu]] = {}

    for interval in intervals:
        logging.info(f"[{symbol}] åŠ è½½æœ¬åœ°æ•°æ®: {interval}, æœ€è¿‘ {days} å¤©")
        df = load_local_kline(symbol, interval, days)
        df = ensure_ohlc(df)
        up_f, down_f = detect_fractals(df)
        bis = detect_bis(df, up_f, down_f)
        zhongshus = detect_zhongshu(df, bis)

        interval_dfs[interval] = df
        bis_map[interval] = bis
        zs_map[interval] = zhongshus

        logging.info(
            f"[{symbol}][{interval}] åˆ†å‹: {len(up_f)+len(down_f)}, ç¬”: {len(bis)}, ä¸­æ¢: {len(zhongshus)}"
        )

    return MultiLevelContext(symbol=symbol, interval_dfs=interval_dfs, bis=bis_map, zhongshus=zs_map)


# ===================== AI è¯„åˆ†æ¨¡å‹ï¼ˆç®€åŒ–ç‰ˆï¼‰ =====================


def compute_trend_strength(df: pd.DataFrame, window_short: int = 20, window_long: int = 60) -> float:
    """
    ç®€åŒ–è¶‹åŠ¿å¼ºåº¦ï¼š
    - çŸ­æœŸå‡çº¿ä¸é•¿æœŸå‡çº¿çš„å·®å¼‚ & æ–œç‡
    - è¿”å› [-1, 1]ï¼Œ>0 ä¸ºä¸Šå‡è¶‹åŠ¿ï¼Œ<0 ä¸ºä¸‹é™è¶‹åŠ¿
    """
    closes = df["close"].values
    if len(closes) < window_long + 2:
        return 0.0

    short_ma = pd.Series(closes).rolling(window_short).mean().iloc[-1]
    long_ma = pd.Series(closes).rolling(window_long).mean().iloc[-1]

    # æ–œç‡ï¼ˆè¿‘å‡ æ ¹çŸ­æœŸå‡çº¿å˜åŒ–ï¼‰
    short_series = pd.Series(closes).rolling(window_short).mean().dropna()
    if len(short_series) < 5:
        slope = 0.0
    else:
        slope = short_series.iloc[-1] - short_series.iloc[-5]

    raw = 0.0
    if long_ma != 0 and not np.isnan(long_ma):
        raw = (short_ma - long_ma) / abs(long_ma)

    raw += slope / (abs(long_ma) + 1e-9)

    return float(max(-1.0, min(1.0, raw)))


def ai_score_signal(
    ctx: MultiLevelContext,
    base_interval: str,
    signal_index: int,
    direction: str,
) -> float:
    """
    å¤šçº§åˆ« AI è¯„åˆ†ï¼ˆé›å½¢ï¼‰ï¼š
    - 4h / 1h / 15m è¶‹åŠ¿å…±æŒ¯
    - åˆ†æ•°èŒƒå›´ [0,1]
    """
    weights = {"4h": 0.4, "1h": 0.3, "15m": 0.3}
    score = 0.0

    for interval, w in weights.items():
        df = ctx.interval_dfs.get(interval)
        if df is None or len(df) < 100:
            continue

        trend = compute_trend_strength(df)
        if direction == "long":
            contrib = max(0.0, trend) * w
        else:
            contrib = max(0.0, -trend) * w

        score += contrib

    # å½’ä¸€åˆ° [0,1]
    return float(max(0.0, min(1.0, score)))


# ===================== é£æ§æ¨¡å—ï¼ˆRRâ‰¥2 é›å½¢ï¼‰ =====================


def compute_atr(df: pd.DataFrame, period: int = 14) -> float:
    high = df["high"]
    low = df["low"]
    close = df["close"]

    prev_close = close.shift(1)
    tr = pd.concat(
        [
            (high - low),
            (high - prev_close).abs(),
            (low - prev_close).abs(),
        ],
        axis=1,
    ).max(axis=1)

    atr = tr.rolling(period).mean().iloc[-1]
    return float(atr) if not np.isnan(atr) else float(tr.mean())


def compute_risk_for_signal(
    df_exec: pd.DataFrame,
    idx: int,
    direction: str,
    rr_target: float = 2.0,
) -> Tuple[float, float, float]:
    """
    åŸºäº ATR çš„ç®€åŒ–ç»“æ„æ­¢æŸ/æ­¢ç›ˆï¼š
    - æ­¢æŸ: entry Â± 1 ATR
    - æ­¢ç›ˆ: entry Â± rr_target * ATR
    """
    closes = df_exec["close"].values
    entry_price = float(closes[idx])
    atr = compute_atr(df_exec)

    if atr <= 0 or np.isnan(atr):
        atr = entry_price * 0.002  # fallback 0.2%

    if direction == "long":
        sl = entry_price - atr
        tp = entry_price + rr_target * atr
    else:
        sl = entry_price + atr
        tp = entry_price - rr_target * atr

    rr = abs(tp - entry_price) / max(1e-9, abs(entry_price - sl))
    return sl, tp, rr


# ===================== ä¿¡å·ç”Ÿæˆå™¨ï¼ˆå¤šçº§åˆ« + æ‰§è¡Œçº§åˆ«ï¼‰ =====================


def generate_signals_v19(
    ctx: MultiLevelContext,
    exec_interval: str = "5m",
    rr_target: float = 2.0,
    min_score: float = 0.6,
) -> List[ChanSignal]:
    """
    éå®Œç¾ç¼ è®ºç‰ˆï¼Œä½†å¯è·‘ã€å¯è¿­ä»£ï¼š
    - åœ¨æ‰§è¡Œçº§åˆ«ä¸Šä½¿ç”¨ç®€åŒ–è¶‹åŠ¿åè½¬é€»è¾‘
    - ç»“åˆå¤šçº§åˆ« AI è¯„åˆ†è¿›è¡Œè¿‡æ»¤
    """
    df_exec = ctx.interval_dfs[exec_interval]
    closes = df_exec["close"].values

    signals: List[ChanSignal] = []

    # ç®€åŒ–è¶‹åŠ¿åè½¬ï¼šçŸ­å‡çº¿çªç ´é•¿å‡çº¿
    short_win = 10
    long_win = 30
    close_s = pd.Series(closes)
    short_ma = close_s.rolling(short_win).mean()
    long_ma = close_s.rolling(long_win).mean()

    last_dir: Optional[str] = None

    for i in range(long_win + 5, len(df_exec) - 5):
        if np.isnan(short_ma.iloc[i]) or np.isnan(long_ma.iloc[i]):
            continue

        dir_now: Optional[str] = None
        if short_ma.iloc[i] > long_ma.iloc[i] and short_ma.iloc[i - 1] <= long_ma.iloc[i - 1]:
            dir_now = "long"
        elif short_ma.iloc[i] < long_ma.iloc[i] and short_ma.iloc[i - 1] >= long_ma.iloc[i - 1]:
            dir_now = "short"

        if dir_now is None or dir_now == last_dir:
            continue

        # å¤šçº§åˆ« AI è¯„åˆ†
        score = ai_score_signal(ctx, exec_interval, i, dir_now)
        if score < min_score:
            continue

        # é£æ§ï¼ˆRRâ‰¥2ï¼‰
        sl, tp, rr = compute_risk_for_signal(df_exec, i, dir_now, rr_target=rr_target)
        if rr < 1.8:  # ç¨å¾®æ”¾å®½ä¸€ç‚¹
            continue

        kind = "trend_break_buy" if dir_now == "long" else "trend_break_sell"
        sig = ChanSignal(
            index=i,
            price=float(closes[i]),
            kind=kind,
            direction=dir_now,
            score=score,
            rr=rr,
            sl=sl,
            tp=tp,
        )
        signals.append(sig)
        last_dir = dir_now

    logging.info(f"[{ctx.symbol}] ç”Ÿæˆä¿¡å·æ•°é‡: {len(signals)}")
    return signals


# ===================== å›æµ‹ä¸»é€»è¾‘ =====================


def backtest_signals(
    df_exec: pd.DataFrame,
    signals: List[ChanSignal],
    max_hold_bars: int = 200,
) -> Tuple[List[Trade], float]:
    """
    ç®€åŒ–ç‰ˆå›æµ‹ï¼š
    - åŒä¸€æ—¶é—´ä»…æŒæœ‰ä¸€ç¬”ä»“ä½
    - è§¦è¾¾æ­¢æŸ/æ­¢ç›ˆ æˆ– è¶…è¿‡æœ€å¤§æŒä»“ bar æ•°åˆ™å¹³ä»“
    """
    trades: List[Trade] = []
    if not signals:
        return trades, 0.0

    closes = df_exec["close"].values
    highs = df_exec["high"].values
    lows = df_exec["low"].values

    current_pos: Optional[Trade] = None

    for sig in signals:
        if current_pos is not None:
            # å·²æœ‰æŒä»“ï¼Œæš‚æ—¶ä¸å¹¶è¡Œå¼€å¤šä»“ï¼Œç®€å•ç‰ˆæœ¬ç›´æ¥å¿½ç•¥åç»­ä¿¡å·
            continue

        entry_idx = sig.index
        entry_price = sig.price
        direction = sig.direction

        exit_price: Optional[float] = None
        exit_idx: int = entry_idx

        for j in range(entry_idx + 1, min(entry_idx + max_hold_bars, len(df_exec))):
            high = highs[j]
            low = lows[j]

            # å¤šå¤´ï¼šå…ˆçœ‹æ­¢æŸï¼Œå†çœ‹æ­¢ç›ˆï¼ˆä¿å®ˆï¼‰
            if direction == "long":
                if low <= sig.sl:
                    exit_price = sig.sl
                    exit_idx = j
                    break
                if high >= sig.tp:
                    exit_price = sig.tp
                    exit_idx = j
                    break
            else:
                if high >= sig.sl:
                    exit_price = sig.sl
                    exit_idx = j
                    break
                if low <= sig.tp:
                    exit_price = sig.tp
                    exit_idx = j
                    break

        if exit_price is None:
            # æœªè§¦å‘æ­¢ç›ˆ/æ­¢æŸï¼Œç”¨æœ€åä¸€ä¸ªå¯è§ close å¹³ä»“
            exit_idx = min(entry_idx + max_hold_bars, len(df_exec) - 1)
            exit_price = float(closes[exit_idx])

        trade = Trade(
            entry_index=entry_idx,
            exit_index=exit_idx,
            entry_price=entry_price,
            exit_price=exit_price,
            direction=direction,
        )
        trades.append(trade)

    total_pnl = sum(t.pnl for t in trades)
    return trades, total_pnl


def run_symbol_v19(
    symbol: str,
    days: int,
    intervals: Optional[List[str]] = None,
) -> Dict[str, float]:
    if intervals is None:
        intervals = ["4h", "1h", "15m", "5m"]

    logging.info(f"========== å¼€å§‹å›æµ‹ V19: {symbol} ==========")
    ctx = build_multilevel_context(symbol, intervals, days)
    df_exec = ctx.interval_dfs["5m"]

    signals = generate_signals_v19(ctx, exec_interval="5m")
    trades, total_pnl = backtest_signals(df_exec, signals)

    wins = sum(1 for t in trades if t.pnl > 0)
    losses = sum(1 for t in trades if t.pnl <= 0)

    logging.info(f"[{symbol}] äº¤æ˜“ç¬”æ•°: {len(trades)}, èƒœç‡: {wins / max(1, len(trades)):.2f}, æ€»æ”¶ç›Š: {total_pnl:.4f}")

    return {
        "symbol": symbol,
        "trades": len(trades),
        "wins": wins,
        "losses": losses,
        "pnl": total_pnl,
    }


# ===================== CLI å…¥å£ =====================


def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser(
        description="SmartBacktest V19 - å¤šçº§åˆ«ç¼ è®º + AI è¯„åˆ† å›æµ‹å¼•æ“ï¼ˆé›å½¢ç‰ˆï¼‰"
    )
    p.add_argument(
        "--symbols",
        type=str,
        required=True,
        help="å›æµ‹å¸ç§åˆ—è¡¨ï¼Œä¾‹å¦‚: BTCUSDT,ETHUSDT,BNBUSDT",
    )
    p.add_argument(
        "--days",
        type=int,
        default=90,
        help="å›æµ‹åŒºé—´å¤©æ•°ï¼ˆå¯¹æ‰€æœ‰å‘¨æœŸç»Ÿä¸€ä½¿ç”¨ï¼‰",
    )
    return p.parse_args()


def main():
    args = parse_args()
    syms = [s.strip() for s in args.symbols.split(",") if s.strip()]

    total_pnl = 0.0
    total_trades = 0
    total_wins = 0

    for sym in syms:
        try:
            res = run_symbol_v19(sym, args.days)
        except Exception as e:
            logging.exception(f"[{sym}] å›æµ‹å¤±è´¥: {e}")
            continue

        total_pnl += res["pnl"]
        total_trades += res["trades"]
        total_wins += res["wins"]

    print("\n========== ğŸ“ˆ V19 å¤šçº§åˆ«ç¼ è®º AI å›æµ‹æˆ˜æŠ¥ ==========")
    print(f"ğŸ’° æ€»æ”¶ç›Š: {total_pnl:.4f}")
    print(f"ğŸ”¢ æ€»äº¤æ˜“æ•°: {total_trades}")
    if total_trades > 0:
        print(f"ğŸ¯ ç»¼åˆèƒœç‡: {total_wins / total_trades:.2f}")
    else:
        print("ğŸ¯ ç»¼åˆèƒœç‡: N/A (æ— äº¤æ˜“)")


if __name__ == "__main__":
    main()
