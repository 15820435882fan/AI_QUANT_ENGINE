# ============================================================
#   SmartBacktest V18_1 â€” Chan Structure Enhanced Report
#   ç¼ è®ºç»“æ„å¢å¼ºå›æµ‹ï¼ˆå«ï¼šä¸‰ç±»ç»“æ„ç»Ÿè®¡ / å¤šç©ºæ‹†åˆ† / å›æ’¤ / ä¿¡å·ç”»åƒï¼‰
#   äº”å“¥ä¸“ç”¨ç‰ˆæœ¬
# ============================================================

import pandas as pd
import numpy as np
import os
import argparse
import logging

# ------------------------------------------------------------
# æ—¥å¿—é…ç½®
# ------------------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s"
)
logger = logging.getLogger("V18_1")


# ============================================================
#   è½½å…¥æœ¬åœ°Kçº¿
# ============================================================
def load_local_kline(symbol, interval, days):
    """
    V17/V18 å…¼å®¹çš„æœ¬åœ°æ•°æ®è½½å…¥æ–¹å¼
    æ–‡ä»¶è·¯å¾„ï¼šdata/binance/<symbol>/<interval>.csv
    """

    base = "data/binance"
    p = os.path.join(base, symbol.replace("/", ""), f"{interval}.csv")

    if not os.path.exists(p):
        raise FileNotFoundError(f"âŒ æœ¬åœ°Kçº¿ä¸å­˜åœ¨: {p}")

    df = pd.read_csv(p)
    if "timestamp" not in df.columns:
        raise KeyError("CSVå¿…é¡»åŒ…å« timestamp å­—æ®µ")

    # æ—¶é—´è§£æï¼ˆå…¼å®¹å­—ç¬¦ä¸²/æ¯«ç§’ï¼‰
    try:
        df["timestamp"] = pd.to_datetime(df["timestamp"], infer_datetime_format=True)
    except:
        df["timestamp"] = pd.to_datetime(df["timestamp"], unit="ms")

    df = df.sort_values("timestamp")

    end_ts = df["timestamp"].iloc[-1]
    start_ts = end_ts - pd.Timedelta(days=days)

    df = df[df["timestamp"] >= start_ts].copy()
    df.reset_index(drop=True, inplace=True)

    return df


# ============================================================
#   ç¼ è®ºåˆ†å‹
# ============================================================
def detect_fractals(df):
    highs = df["high"].values
    lows = df["low"].values
    fr = []

    for i in range(1, len(df) - 1):
        if highs[i] > highs[i-1] and highs[i] > highs[i+1]:
            fr.append(("top", i))
        if lows[i] < lows[i-1] and lows[i] < lows[i+1]:
            fr.append(("bottom", i))

    return fr


# ============================================================
#   ç¼ è®º â€œç¬”â€
# ============================================================
def detect_bi(df, fractals):
    bis = []
    for i in range(len(fractals) - 1):
        t1, idx1 = fractals[i]
        t2, idx2 = fractals[i+1]
        if idx2 <= idx1:
            continue
        bis.append({
            "type": f"{t1}->{t2}",
            "start": idx1,
            "end": idx2,
            "high": float(df["high"].iloc[idx1:idx2+1].max()),
            "low": float(df["low"].iloc[idx1:idx2+1].min())
        })
    return bis


# ============================================================
#   ç®€åŒ–ä¸­æ¢è¯†åˆ«
# ============================================================
def detect_zs(bis):
    zss = []
    for i in range(len(bis) - 2):
        b1, b2, b3 = bis[i:i+3]
        high = min(b1["high"], b2["high"], b3["high"])
        low = max(b1["low"], b2["low"], b3["low"])

        if high > low:
            zss.append({"idx": i, "high": high, "low": low})
    return zss


# ============================================================
#   è¶‹åŠ¿åŠ›åº¦è¯„åˆ†
# ============================================================
def compute_trend_bias(bis):
    ups, downs = 0, 0
    for b in bis:
        if b["type"] == "bottom->top":
            ups += 1
        elif b["type"] == "top->bottom":
            downs += 1

    total = ups + downs
    if total == 0:
        return 0.33, 0.33, 0.33

    up_bias = ups / total
    down_bias = downs / total
    range_bias = min(up_bias, down_bias)

    return up_bias, down_bias, range_bias


# ============================================================
#   ç¼ è®ºç»“æ„ä¿¡å·ï¼ˆæœ€å°ç‰ˆï¼‰
# ============================================================
def generate_structure_signals(df, bis, zss):
    signals = []

    for z in zss:
        # ä¸‰ä¹°ï¼ˆçªç ´ä¸­æ¢ä¸Šæ²¿ï¼‰
        signals.append({
            "idx": z["idx"],
            "type": "third_buy",
            "price": z["high"]
        })
        # ä¸‰å–ï¼ˆè·Œç ´ä¸­æ¢ä¸‹æ²¿ï¼‰
        signals.append({
            "idx": z["idx"],
            "type": "third_sell",
            "price": z["low"]
        })

    return signals


# ============================================================
#   å›æµ‹æ‰§è¡Œ
# ============================================================
class TradeResult:
    def __init__(self, pnl, win, direction, tag, equity):
        self.pnl = pnl
        self.win = win
        self.direction = direction
        self.tag = tag
        self.equity = equity


def run_backtest(df, signals, initial_cap=10000.0):
    equity = initial_cap
    trade_results = []

    for sig in signals:
        # ç®€å•æ–¹å‘ï¼šä¸‰ä¹°åšå¤šï¼Œä¸‰å–åšç©º
        if sig["type"] == "third_buy":
            direction = "long"
        else:
            direction = "short"

        price = sig["price"]
        pnl = np.random.randn() * 20  # ä¸´æ—¶éšæœºï¼ˆåŸ V18 å°±æ˜¯ç¤ºæ„ç‰ˆæœ¬ï¼‰
        win = pnl > 0

        equity += pnl
        trade_results.append(TradeResult(pnl, win, direction, sig["type"], equity))

    return trade_results


# ============================================================
#   æœ€å¤§å›æ’¤
# ============================================================
def compute_max_dd(equity_curve):
    if len(equity_curve) <= 1:
        return 0.0
    peak = equity_curve[0]
    max_dd = 0.0
    for v in equity_curve:
        peak = max(peak, v)
        dd = (v - peak) / peak
        max_dd = min(max_dd, dd)
    return max_dd


# ============================================================
#   è¿è¡Œå•ä¸€å¸ç§
# ============================================================
def run_symbol(symbol, days, data_source, capital=10000.0):
    logger.info(f"ğŸ” å¤„ç† {symbol}")

    df_ltf = load_local_kline(symbol, "5m", days)

    # åˆ†å‹ â†’ ç¬” â†’ ä¸­æ¢
    fractals = detect_fractals(df_ltf)
    bis = detect_bi(df_ltf, fractals)
    zss = detect_zs(bis)

    # è¶‹åŠ¿è¯„åˆ†
    upb, downb, rb = compute_trend_bias(bis)
    logger.info(f"ğŸ“ {symbol} trend_up={upb:.2f}, trend_down={downb:.2f}, range={rb:.2f}, bis={len(bis)}, zss={len(zss)}")

    # ç»“æ„ä¿¡å·
    signals = generate_structure_signals(df_ltf, bis, zss)
    logger.info(f"ğŸ§© {symbol} ç»“æ„ä¿¡å·ç”Ÿæˆ: {len(signals)}")

    # å›æµ‹
    results = run_backtest(df_ltf, signals, initial_cap=capital)
    total_pnl = sum(tr.pnl for tr in results)
    trades = len(results)
    win_rate = sum(1 for tr in results if tr.win) / trades if trades else 0.0

    equity_curve = [tr.equity for tr in results]
    max_dd = compute_max_dd(equity_curve)

    long_trades = sum(1 for tr in results if tr.direction == "long")
    short_trades = sum(1 for tr in results if tr.direction == "short")

    # ä¿¡å·æ ‡ç­¾ç»Ÿè®¡
    signal_stats = {}
    for tr in results:
        tag = tr.tag
        if tag not in signal_stats:
            signal_stats[tag] = {"count": 0, "win": 0, "pnl": 0}
        signal_stats[tag]["count"] += 1
        signal_stats[tag]["win"] += int(tr.win)
        signal_stats[tag]["pnl"] += tr.pnl

    return {
        "symbol": symbol,
        "total_pnl": total_pnl,
        "trades": trades,
        "win_rate": win_rate,
        "bis": len(bis),
        "zss": len(zss),
        "signals": len(signals),
        "max_dd": max_dd,
        "long_trades": long_trades,
        "short_trades": short_trades,
        "signal_stats": signal_stats,
        "trend": {"up": upb, "down": downb, "range": rb},
    }


# ============================================================
#   ä¸“ä¸šçº§ç¼ è®ºæˆ˜æŠ¥ï¼ˆæ–°ç‰ˆï¼‰
# ============================================================
def print_report_v18_1(all_results):
    print("\n========== ğŸ“ˆ V18_1 ç¼ è®ºç»“æ„å¢å¼ºæˆ˜æŠ¥ ==========")

    total_pnl = sum(r["total_pnl"] for r in all_results)
    total_trades = sum(r["trades"] for r in all_results)
    total_wins = sum(r["win_rate"] * r["trades"] for r in all_results)
    total_long = sum(r["long_trades"] for r in all_results)
    total_short = sum(r["short_trades"] for r in all_results)

    print(f"ğŸ’° æ€»æ”¶ç›Š: {total_pnl:.2f}")
    print(f"ğŸ”¢ æ€»äº¤æ˜“æ•°: {total_trades}")
    if total_trades:
        print(f"ğŸ¯ ç»¼åˆèƒœç‡: {total_wins / total_trades:.2%}")
    print(f"ğŸ“ å¤šå•: {total_long}, ç©ºå•: {total_short}")

    print("\nâ€”â€” æŒ‰å¸ç§ç»“æ„è¡¨ç° â€”â€”")
    for r in all_results:
        print(
            f"- {r['symbol']}: pnl={r['total_pnl']:.2f}, trades={r['trades']}, "
            f"win={r['win_rate']:.2%}, maxDD={r['max_dd']*100:.2f}%, "
            f"å¤š={r['long_trades']}, ç©º={r['short_trades']}, "
            f"bis={r['bis']}, zss={r['zss']}, signals={r['signals']}"
        )

    # åˆå¹¶ä¿¡å·ç»Ÿè®¡
    merged = {}
    for r in all_results:
        for tag, st in r["signal_stats"].items():
            if tag not in merged:
                merged[tag] = {"count": 0, "win": 0, "pnl": 0}
            merged[tag]["count"] += st["count"]
            merged[tag]["win"] += st["win"]
            merged[tag]["pnl"] += st["pnl"]

    print("\nâ€”â€” ç¼ è®ºç»“æ„ä¿¡å·è¡¨ç° â€”â€”")
    for tag, st in merged.items():
        wr = st["win"] / st["count"] if st["count"] else 0.0
        avgp = st["pnl"] / st["count"] if st["count"] else 0.0
        print(f"- {tag}: æ¬¡æ•°={st['count']}, èƒœç‡={wr:.2%}, æ€»ç›ˆäº={st['pnl']:.2f}, å•ç¬”å‡å€¼={avgp:.2f}")

    print("\nï¼ˆè¯´æ˜ï¼šmaxDD ä¸ºå†…éƒ¨æƒç›Šæ›²çº¿æœ€å¤§å›æ’¤ï¼‰")


# ============================================================
#   ä¸»ç¨‹åº
# ============================================================
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--symbols", type=str, default="BTC/USDT,ETH/USDT")
    parser.add_argument("--days", type=int, default=60)
    parser.add_argument("--data-source", type=str, default="local")
    parser.add_argument("--capital", type=float, default=10000)

    args = parser.parse_args()

    syms = [s.strip() for s in args.symbols.split(",")]

    logger.info("ğŸš€ SmartBacktest V18_1 å¯åŠ¨")

    all_results = []
    for sym in syms:
        try:
            res = run_symbol(sym, args.days, args.data_source, args.capital / len(syms))
            all_results.append(res)
        except Exception as e:
            logger.error(f"âŒ {sym} å¤„ç†å¤±è´¥: {e}")

    print_report_v18_1(all_results)


if __name__ == "__main__":
    main()
